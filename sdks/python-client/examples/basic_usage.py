"""
EngramDB Client Example: Basic Usage

This example demonstrates how to use the EngramDB Python client to interact with the API.
"""
import numpy as np
from engramdb_client import EngramClient, AttributeFilter

def run_example():
    # Initialize the client
    client = EngramClient(api_url="http://localhost:8000/v1")
    
    # Create a database
    print("Creating a new database...")
    db = client.create_database("example_database")
    print(f"Created database with ID: {db.database_id}")
    
    # Create memory nodes
    print("\nCreating memory nodes...")
    
    # Create a node with a vector embedding
    vector1 = np.array([0.1, 0.2, 0.3, 0.4], dtype=np.float32)
    node1 = db.create_node(
        vector=vector1,
        attributes={
            "title": "Example Memory 1",
            "category": "example",
            "importance": 0.8,
        },
        content="This is the first example memory in our database."
    )
    print(f"Created node 1 with ID: {node1.id}")
    
    # Create a node from text content (embeddings generated by API)
    node2 = db.create_node_from_content(
        content="This is the second example memory, created directly from text content.",
        model="default",
        attributes={
            "title": "Example Memory 2",
            "category": "example",
            "importance": 0.6,
        }
    )
    print(f"Created node 2 with ID: {node2.id}")
    
    # Create more nodes
    vector3 = np.array([0.15, 0.25, 0.35, 0.45], dtype=np.float32)
    node3 = db.create_node(
        vector=vector3,
        attributes={
            "title": "Important Meeting Notes",
            "category": "meeting",
            "importance": 0.9,
        },
        content="Notes from the quarterly planning meeting with the executive team."
    )
    print(f"Created node 3 with ID: {node3.id}")
    
    vector4 = np.array([0.2, 0.3, 0.4, 0.5], dtype=np.float32)
    node4 = db.create_node(
        vector=vector4,
        attributes={
            "title": "Research Paper Summary",
            "category": "research",
            "importance": 0.75,
        },
        content="Summary of the latest research paper on vector databases and semantic search."
    )
    print(f"Created node 4 with ID: {node4.id}")
    
    # Create connections between nodes
    print("\nCreating connections between nodes...")
    node1.connect(node2.id, "Association", strength=0.8)
    print(f"Connected node 1 to node 2 with type 'Association'")
    
    node1.connect(node3.id, "Reference", strength=0.6)
    print(f"Connected node 1 to node 3 with type 'Reference'")
    
    node3.connect(node4.id, "Causation", strength=0.7)
    print(f"Connected node 3 to node 4 with type 'Causation'")
    
    # Search using vector similarity
    print("\nSearching for similar nodes to node 1...")
    search_results = db.search(
        vector=vector1,
        limit=3,
        threshold=0.0,
        include_connections=True
    )
    
    print(f"Found {len(search_results)} similar nodes:")
    for i, (node, similarity) in enumerate(search_results, 1):
        print(f"  {i}. {node.get_attribute('title')} (similarity: {similarity:.4f})")
        if node.connections():
            print(f"     Connections: {len(node.connections())}")
            for conn in node.connections():
                print(f"     - Connected to: {conn['target_id']}, Type: {conn['type_name']}")
    
    # Search using text query
    print("\nSearching with text query...")
    text_results = db.search_text(
        text="research paper",
        limit=2,
        include_vectors=False
    )
    
    print(f"Found {len(text_results)} nodes matching 'research paper':")
    for i, (node, similarity) in enumerate(text_results, 1):
        print(f"  {i}. {node.get_attribute('title')} (similarity: {similarity:.4f})")
        print(f"     Content: {node.content()}")
    
    # Filter nodes by attributes
    print("\nFiltering nodes by category...")
    category_filter = AttributeFilter.equals("category", "meeting")
    importance_filter = AttributeFilter.greater_than("importance", 0.7)
    
    filter_results = db.search(
        filters=[category_filter, importance_filter],
        limit=10,
        include_connections=True
    )
    
    print(f"Found {len(filter_results)} high-importance meeting nodes:")
    for i, (node, similarity) in enumerate(filter_results, 1):
        print(f"  {i}. {node.get_attribute('title')}")
        print(f"     Importance: {node.get_attribute('importance')}")
        print(f"     Content: {node.content()}")
    
    # Update a node
    print("\nUpdating node 1...")
    node1.set_attribute("importance", 0.95)
    node1.set_content("Updated content for the first example memory.")
    node1.save()
    print("Node 1 updated with new importance and content.")
    
    # Refresh a node from the database
    node1.refresh()
    print(f"Node 1 refreshed from database.")
    print(f"Current importance: {node1.get_attribute('importance')}")
    print(f"Current content: {node1.content()}")
    
    # List all nodes
    print("\nListing all nodes in the database...")
    all_nodes = db.list_nodes()
    print(f"Found {len(all_nodes)} total nodes:")
    for i, node in enumerate(all_nodes, 1):
        print(f"  {i}. {node.get_attribute('title')} ({node.id})")
    
    # Clean up (optional)
    print("\nCleaning up...")
    for node in [node1, node2, node3, node4]:
        node.delete()
    print("All nodes deleted.")
    
    print("\nBasic usage example completed!")

if __name__ == "__main__":
    run_example()